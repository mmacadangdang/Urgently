{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Data Processor\n",
    "Predicts whether a 311 service request is \"urgent\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mahlo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.datasets import load_files\n",
    "nltk.download('stopwords')\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import sqlalchemy as db\n",
    "from sqlalchemy import create_engine, MetaData, Table, Column, Integer\n",
    "from sqlalchemy.orm import sessionmaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data: Small sample data\n",
    "# df = pd.read_csv(\n",
    "#     'Sample CSVs/2019-sample-small.csv', header=0)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>service_request_id</th>\n",
       "      <th>service_request_parent_id</th>\n",
       "      <th>date_requested</th>\n",
       "      <th>case_age_days</th>\n",
       "      <th>service_name</th>\n",
       "      <th>case_record_type</th>\n",
       "      <th>date_updated</th>\n",
       "      <th>status</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>council_district</th>\n",
       "      <th>comm_plan_code</th>\n",
       "      <th>comm_plan_name</th>\n",
       "      <th>park_name</th>\n",
       "      <th>case_origin</th>\n",
       "      <th>referred</th>\n",
       "      <th>public_description</th>\n",
       "      <th>urgent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39984</td>\n",
       "      <td>2522790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-27T15:39:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>72 Hour Violation</td>\n",
       "      <td>Parking</td>\n",
       "      <td>2019-03-04T00:00:00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>32.73060</td>\n",
       "      <td>-117.226</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Peninsula</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abandoned car has been sitting in same spot on...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2475208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-01T00:20:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "      <td>TSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Referred</td>\n",
       "      <td>32.70230</td>\n",
       "      <td>-117.093</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Encanto Neighborhoods</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>This report has been referred to Police CRO ? ...</td>\n",
       "      <td>Ongoing loud fireworks in area near El Rey Tra...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2475209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-01T00:21:00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Litter</td>\n",
       "      <td>ESD Complaint/Report</td>\n",
       "      <td>2019-01-15T00:00:00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>32.71980</td>\n",
       "      <td>-117.060</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Encanto Neighborhoods</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3 bags of garbage and one box</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2475210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-01T01:06:00</td>\n",
       "      <td>189.0</td>\n",
       "      <td>Street Sweeping</td>\n",
       "      <td>TSW</td>\n",
       "      <td>2019-07-09T00:00:00</td>\n",
       "      <td>Closed</td>\n",
       "      <td>32.70216</td>\n",
       "      <td>-117.052</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Skyline-Paradise Hills</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Web</td>\n",
       "      <td>NaN</td>\n",
       "      <td>North side of Skyline Drive from Cielo to Wood...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2475212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-01T01:28:00</td>\n",
       "      <td>400.0</td>\n",
       "      <td>Street Light Out</td>\n",
       "      <td>TSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In Process</td>\n",
       "      <td>32.79611</td>\n",
       "      <td>-117.125</td>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Serra Mesa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Street light not working.</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  service_request_id  service_request_parent_id       date_requested  \\\n",
       "0  39984             2522790                        NaN  2019-02-27T15:39:00   \n",
       "1      2             2475208                        NaN  2019-01-01T00:20:00   \n",
       "2      3             2475209                        NaN  2019-01-01T00:21:00   \n",
       "3      4             2475210                        NaN  2019-01-01T01:06:00   \n",
       "4      6             2475212                        NaN  2019-01-01T01:28:00   \n",
       "\n",
       "   case_age_days       service_name      case_record_type  \\\n",
       "0            5.0  72 Hour Violation               Parking   \n",
       "1            NaN              Other                   TSW   \n",
       "2           15.0             Litter  ESD Complaint/Report   \n",
       "3          189.0    Street Sweeping                   TSW   \n",
       "4          400.0   Street Light Out                   TSW   \n",
       "\n",
       "          date_updated      status       lat      lng  council_district  \\\n",
       "0  2019-03-04T00:00:00      Closed  32.73060 -117.226               2.0   \n",
       "1                  NaN    Referred  32.70230 -117.093               4.0   \n",
       "2  2019-01-15T00:00:00      Closed  32.71980 -117.060               4.0   \n",
       "3  2019-07-09T00:00:00      Closed  32.70216 -117.052               4.0   \n",
       "4                  NaN  In Process  32.79611 -117.125               7.0   \n",
       "\n",
       "   comm_plan_code          comm_plan_name park_name case_origin  \\\n",
       "0            30.0               Peninsula       NaN         Web   \n",
       "1            11.0   Encanto Neighborhoods       NaN      Mobile   \n",
       "2            11.0   Encanto Neighborhoods       NaN      Mobile   \n",
       "3            44.0  Skyline-Paradise Hills       NaN         Web   \n",
       "4            35.0              Serra Mesa       NaN      Mobile   \n",
       "\n",
       "                                            referred  \\\n",
       "0                                                NaN   \n",
       "1  This report has been referred to Police CRO ? ...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                  public_description urgent  \n",
       "0  Abandoned car has been sitting in same spot on...     no  \n",
       "1  Ongoing loud fireworks in area near El Rey Tra...     no  \n",
       "2                      3 bags of garbage and one box     no  \n",
       "3  North side of Skyline Drive from Cielo to Wood...     no  \n",
       "4                          Street light not working.     no  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Load data: After manual classification work\n",
    "# df = pd.read_csv(\n",
    "#     'Sample CSVs/Working CSV.csv', header=0)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>service_request_id</th>\n",
       "      <th>service_request_parent_id</th>\n",
       "      <th>date_requested</th>\n",
       "      <th>case_age_days</th>\n",
       "      <th>service_name</th>\n",
       "      <th>case_record_type</th>\n",
       "      <th>date_updated</th>\n",
       "      <th>status</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>council_district</th>\n",
       "      <th>comm_plan_code</th>\n",
       "      <th>comm_plan_name</th>\n",
       "      <th>park_name</th>\n",
       "      <th>case_origin</th>\n",
       "      <th>referred</th>\n",
       "      <th>public_description</th>\n",
       "      <th>urgent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39984</td>\n",
       "      <td>2522790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>72 Hour Violation</td>\n",
       "      <td>Parking</td>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>Closed</td>\n",
       "      <td>32.73060</td>\n",
       "      <td>-117.226</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Peninsula</td>\n",
       "      <td>None</td>\n",
       "      <td>Web</td>\n",
       "      <td>None</td>\n",
       "      <td>Abandoned car has been sitting in same spot on...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2475208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Other</td>\n",
       "      <td>TSW</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Referred</td>\n",
       "      <td>32.70230</td>\n",
       "      <td>-117.093</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Encanto Neighborhoods</td>\n",
       "      <td>None</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>This report has been referred to Police CRO ? ...</td>\n",
       "      <td>Ongoing loud fireworks in area near El Rey Tra...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2475209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Litter</td>\n",
       "      <td>ESD Complaint/Report</td>\n",
       "      <td>2019-01-15</td>\n",
       "      <td>Closed</td>\n",
       "      <td>32.71980</td>\n",
       "      <td>-117.060</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Encanto Neighborhoods</td>\n",
       "      <td>None</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>None</td>\n",
       "      <td>3 bags of garbage and one box</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2475210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>189.0</td>\n",
       "      <td>Street Sweeping</td>\n",
       "      <td>TSW</td>\n",
       "      <td>2019-07-09</td>\n",
       "      <td>Closed</td>\n",
       "      <td>32.70216</td>\n",
       "      <td>-117.052</td>\n",
       "      <td>4.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Skyline-Paradise Hills</td>\n",
       "      <td>None</td>\n",
       "      <td>Web</td>\n",
       "      <td>None</td>\n",
       "      <td>North side of Skyline Drive from Cielo to Wood...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2475212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>400.0</td>\n",
       "      <td>Street Light Out</td>\n",
       "      <td>TSW</td>\n",
       "      <td>NaT</td>\n",
       "      <td>In Process</td>\n",
       "      <td>32.79611</td>\n",
       "      <td>-117.125</td>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Serra Mesa</td>\n",
       "      <td>None</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>None</td>\n",
       "      <td>Street light not working.</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  service_request_id  service_request_parent_id date_requested  \\\n",
       "0  39984             2522790                        NaN     2019-02-27   \n",
       "1      2             2475208                        NaN     2019-01-01   \n",
       "2      3             2475209                        NaN     2019-01-01   \n",
       "3      4             2475210                        NaN     2019-01-01   \n",
       "4      6             2475212                        NaN     2019-01-01   \n",
       "\n",
       "   case_age_days       service_name      case_record_type date_updated  \\\n",
       "0            5.0  72 Hour Violation               Parking   2019-03-04   \n",
       "1            NaN              Other                   TSW          NaT   \n",
       "2           15.0             Litter  ESD Complaint/Report   2019-01-15   \n",
       "3          189.0    Street Sweeping                   TSW   2019-07-09   \n",
       "4          400.0   Street Light Out                   TSW          NaT   \n",
       "\n",
       "       status       lat      lng  council_district  comm_plan_code  \\\n",
       "0      Closed  32.73060 -117.226               2.0            30.0   \n",
       "1    Referred  32.70230 -117.093               4.0            11.0   \n",
       "2      Closed  32.71980 -117.060               4.0            11.0   \n",
       "3      Closed  32.70216 -117.052               4.0            44.0   \n",
       "4  In Process  32.79611 -117.125               7.0            35.0   \n",
       "\n",
       "           comm_plan_name park_name case_origin  \\\n",
       "0               Peninsula      None         Web   \n",
       "1   Encanto Neighborhoods      None      Mobile   \n",
       "2   Encanto Neighborhoods      None      Mobile   \n",
       "3  Skyline-Paradise Hills      None         Web   \n",
       "4              Serra Mesa      None      Mobile   \n",
       "\n",
       "                                            referred  \\\n",
       "0                                               None   \n",
       "1  This report has been referred to Police CRO ? ...   \n",
       "2                                               None   \n",
       "3                                               None   \n",
       "4                                               None   \n",
       "\n",
       "                                  public_description urgent  \n",
       "0  Abandoned car has been sitting in same spot on...     no  \n",
       "1  Ongoing loud fireworks in area near El Rey Tra...     no  \n",
       "2                      3 bags of garbage and one box     no  \n",
       "3  North side of Skyline Drive from Cielo to Wood...     no  \n",
       "4                          Street light not working.     no  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data: From SQL server\n",
    "engine = db.create_engine('postgresql://postgres:88653680Dd!@localhost/311_requests')\n",
    "connection = engine.connect()\n",
    "query = \"select * from requests_raw;\"\n",
    "df = pd.read_sql_query(query, connection)\n",
    "connection.close()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>service_request_id</th>\n",
       "      <th>service_request_parent_id</th>\n",
       "      <th>date_requested</th>\n",
       "      <th>service_name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>public_description</th>\n",
       "      <th>urgent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39984</td>\n",
       "      <td>2522790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-27</td>\n",
       "      <td>72 Hour Violation</td>\n",
       "      <td>32.73060</td>\n",
       "      <td>-117.226</td>\n",
       "      <td>Abandoned car has been sitting in same spot on...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2475208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Other</td>\n",
       "      <td>32.70230</td>\n",
       "      <td>-117.093</td>\n",
       "      <td>Ongoing loud fireworks in area near El Rey Tra...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2475209</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Litter</td>\n",
       "      <td>32.71980</td>\n",
       "      <td>-117.060</td>\n",
       "      <td>3 bags of garbage and one box</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2475210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Street Sweeping</td>\n",
       "      <td>32.70216</td>\n",
       "      <td>-117.052</td>\n",
       "      <td>North side of Skyline Drive from Cielo to Wood...</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2475212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>Street Light Out</td>\n",
       "      <td>32.79611</td>\n",
       "      <td>-117.125</td>\n",
       "      <td>Street light not working.</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  service_request_id  service_request_parent_id date_requested  \\\n",
       "0  39984             2522790                        NaN     2019-02-27   \n",
       "1      2             2475208                        NaN     2019-01-01   \n",
       "2      3             2475209                        NaN     2019-01-01   \n",
       "3      4             2475210                        NaN     2019-01-01   \n",
       "4      6             2475212                        NaN     2019-01-01   \n",
       "\n",
       "        service_name       lat      lng  \\\n",
       "0  72 Hour Violation  32.73060 -117.226   \n",
       "1              Other  32.70230 -117.093   \n",
       "2             Litter  32.71980 -117.060   \n",
       "3    Street Sweeping  32.70216 -117.052   \n",
       "4   Street Light Out  32.79611 -117.125   \n",
       "\n",
       "                                  public_description urgent  \n",
       "0  Abandoned car has been sitting in same spot on...     no  \n",
       "1  Ongoing loud fireworks in area near El Rey Tra...     no  \n",
       "2                      3 bags of garbage and one box     no  \n",
       "3  North side of Skyline Drive from Cielo to Wood...     no  \n",
       "4                          Street light not working.     no  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the irrelevant columns\n",
    "df = df.drop(columns=['case_age_days', 'case_record_type', 'date_updated', 'status', 'council_district', 'comm_plan_code', 'comm_plan_name', 'park_name', 'case_origin', 'referred'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plug the CSV's public_description column and urgent column into X and y\n",
    "X, y = df.public_description, df.urgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "for sen in range(0, len(X)):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "    \n",
    "    # remove all single characters\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # Remove single characters from the start\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    \n",
    "    # Substituting multiple spaces with single space\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Removing prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Lemmatization\n",
    "#     document = document.split()\n",
    "\n",
    "#     document = [stemmer.lemmatize(word) for word in document]\n",
    "#     document = ' '.join(document)\n",
    "    \n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abandoned car has been sitting in same spot on property for 12 months light blue ford 4 door taurus older model ca license 4twk522'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------\n",
    "# Calculate TF-IDF using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Bag of Words to to encode text\n",
    "vectorizer = CountVectorizer(max_features=1500, min_df=1, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the Bag Of Words array to calculate TF-IDF\n",
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.9, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the data to the model\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['yes', 'no', 'yes', ..., 'no', 'no', 'yes'], dtype=object)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a prediction\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10321   885]\n",
      " [ 1896  2345]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.84      0.92      0.88     11206\n",
      "         yes       0.73      0.55      0.63      4241\n",
      "\n",
      "    accuracy                           0.82     15447\n",
      "   macro avg       0.79      0.74      0.75     15447\n",
      "weighted avg       0.81      0.82      0.81     15447\n",
      "\n",
      "0.8199650417556807\n"
     ]
    }
   ],
   "source": [
    "# Perform the evaluation, and print the results\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_classifier', 'wb') as picklefile:\n",
    "    pickle.dump(classifier,picklefile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text_classifier', 'rb') as training_model:\n",
    "    model = pickle.load(training_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10321   885]\n",
      " [ 1896  2345]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.84      0.92      0.88     11206\n",
      "         yes       0.73      0.55      0.63      4241\n",
      "\n",
      "    accuracy                           0.82     15447\n",
      "   macro avg       0.79      0.74      0.75     15447\n",
      "weighted avg       0.81      0.82      0.81     15447\n",
      "\n",
      "0.8199650417556807\n"
     ]
    }
   ],
   "source": [
    "# Test the loaded model to confirm that it has the same results\n",
    "y_pred2 = model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred2))\n",
    "print(classification_report(y_test, y_pred2))\n",
    "print(accuracy_score(y_test, y_pred2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yes' 'no' 'yes' ... 'no' 'no' 'yes']\n"
     ]
    }
   ],
   "source": [
    "# Show the predictions array for comparison\n",
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8199650417556807\n"
     ]
    }
   ],
   "source": [
    "#Show the accuracy score\n",
    "print(accuracy_score(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['yes', 'no', 'yes', ..., 'no', 'no', 'yes'], dtype=object)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert the results into SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = engine.connect()\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session(bind=connection)\n",
    "query = f\"INSERT INTO predictions (prediction) VALUES ({y_pred2})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.add('foo', 'bar') \n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 5000\n",
    "embedding_dim = 64\n",
    "max_length = 200\n",
    "trunc_type = 'post'\n",
    "padding_type = 'post'\n",
    "oov_tok = '<OOV>'\n",
    "training_portion = .8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17163\n",
      "17163\n"
     ]
    }
   ],
   "source": [
    "articles = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "with open(\"Working CSV.csv\", 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        labels.append(row[18])\n",
    "        article = row[17]\n",
    "        for word in STOPWORDS:\n",
    "            token = ' ' + word + ' '\n",
    "            article = article.replace(token, ' ')\n",
    "            article = article.replace(' ', ' ')\n",
    "        articles.append(article)\n",
    "print(len(labels))\n",
    "print(len(articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_size = int(len(articles) * training_portion)\n",
    "\n",
    "train_articles = articles[0: train_size]\n",
    "train_labels = labels[0: train_size]\n",
    "\n",
    "validation_articles = articles[train_size:]\n",
    "validation_labels = labels[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<OOV>': 1,\n",
       " 'street': 2,\n",
       " 'parked': 3,\n",
       " 'trash': 4,\n",
       " 'the': 5,\n",
       " 'i': 6,\n",
       " 'car': 7,\n",
       " 'missed': 8,\n",
       " 'this': 9,\n",
       " 'vehicle': 10}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(train_articles)\n",
    "word_index = tokenizer.word_index\n",
    "dict(list(word_index.items())[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(train_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_padded = pad_sequences(train_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_sequences = tokenizer.texts_to_sequences(validation_articles)\n",
    "validation_padded = pad_sequences(validation_sequences, maxlen=max_length, padding=padding_type, truncating=trunc_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tokenizer = Tokenizer()\n",
    "label_tokenizer.fit_on_texts(labels)\n",
    "\n",
    "training_label_seq = np.array(label_tokenizer.texts_to_sequences(train_labels))\n",
    "validation_label_seq = np.array(label_tokenizer.texts_to_sequences(validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shopping carts ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?\n",
      "---\n",
      "Shopping carts\n"
     ]
    }
   ],
   "source": [
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_article(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
    "print(decode_article(train_padded[10]))\n",
    "print('---')\n",
    "print(train_articles[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          320000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               66048     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 390       \n",
      "=================================================================\n",
      "Total params: 394,694\n",
      "Trainable params: 394,694\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # Add an Embedding layer expecting input vocab of size 5000, and output embedding dimension of size 64 we set at the top\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n",
    "#    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
    "    # use ReLU in place of tanh function since they are very good alternatives of each other.\n",
    "    tf.keras.layers.Dense(embedding_dim, activation='relu'),\n",
    "    # Add a Dense layer with 6 units and softmax activation.\n",
    "    # When we have multiple outputs, softmax convert outputs layers into a probability distribution.\n",
    "    tf.keras.layers.Dense(1, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add drop-out for 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13730 samples, validate on 3433 samples\n",
      "Epoch 1/2\n",
      "13730/13730 - 91s - loss: 0.3051 - accuracy: 0.9047 - val_loss: 1.4616 - val_accuracy: 0.0883\n",
      "Epoch 2/2\n",
      "13730/13730 - 82s - loss: 0.1983 - accuracy: 0.9220 - val_loss: 1.9393 - val_accuracy: 0.1576\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "num_epochs = 2\n",
    "history = model.fit(train_padded, training_label_seq, epochs=num_epochs, validation_data=(validation_padded, validation_label_seq), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts('Consumer complaint narrative with hella more text for some fun')\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.52391485e-05 9.85247374e-01 1.46941487e-02 1.85442805e-05\n",
      "  1.18627613e-05 1.28243291e-05]] no\n"
     ]
    }
   ],
   "source": [
    "new_complaint = ['bunnies with big silly things on heads']\n",
    "seq = tokenizer.texts_to_sequences(new_complaint)\n",
    "padded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "pred = model.predict(padded)\n",
    "labels = ['water', 'no', 'space', 'yes']\n",
    "print(pred, labels[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
